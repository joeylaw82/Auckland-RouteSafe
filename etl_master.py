import pandas as pd
import geopandas as gpd
import requests
import io
import os
import json
from datetime import datetime
import re
from time import sleep 
from urllib.parse import urlencode 
import sys 

# --- 1. é…ç½®å€ (Configuration) ---
POLICE_DATA_URL = os.environ.get("POLICE_DATA_URL") 
MESHBLOCK_BASE_URL = "https://services.arcgis.com/XTtANUDT8Va4DLwI/arcgis/rest/services/nz_meshblocks/FeatureServer/0"
AREA_UNIT_BASE_URL = "https://services2.arcgis.com/vKb0s8tBIA3bdocZ/ArcGIS/rest/services/Area_Unit_2017/FeatureServer/0"
ARCGIS_ROUTES_URL = "https://services2.arcgis.com/JkPEgZJGxhSjYOo0/arcgis/rest/services/BusService/FeatureServer/2/query?where=1%3D1&outFields=*&f=geojson"

AUCKLAND_AUTHORITIES = ['Auckland','Waitemata', 'Counties Manukau', 'Franklin', 'Auckland City'] 

# è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
OUTPUT_DIR = 'data'
OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'route_crime_stats.geojson')
STATS_OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'crime_breakdown.json')
DEBUG_CSV_FILE = os.path.join(OUTPUT_DIR, 'auckland_crime_debug.csv') 

# ğŸ’¥ ä¿®æ­£é»: é™ä½å–®æ¬¡è«‹æ±‚è¨˜éŒ„æ•¸ä»¥æé«˜ ArcGIS æ•¸æ“šä¸‹è¼‰ç©©å®šæ€§
MAX_RECORDS = 500 


# --- 2. è¼”åŠ©å‡½æ•¸ (Helper Functions) ---

def clean_territorial_authority(name: str) -> str:
    """æ¸…ç†è¡Œæ”¿å€åç¨±ã€‚"""
    if pd.isna(name): return ''
    cleaned = re.sub(r'[^\w\s]', '', str(name), flags=re.UNICODE) 
    cleaned = re.sub(r'\s+', ' ', cleaned).strip() 
    return cleaned.upper()

AUCKLAND_AUTHORITIES_CLEANED = [clean_territorial_authority(name) for name in AUCKLAND_AUTHORITIES]


def fetch_arcgis_geometry(base_url: str, id_field: str, out_fields: list) -> gpd.GeoDataFrame:
    """é€šç”¨çš„ ArcGIS åˆ†é ç²å–å¹¾ä½•å‡½æ•¸ã€‚"""
    print(f"   -> æ­£åœ¨ä½¿ç”¨åˆ†é æŠ€è¡“ç²å– {id_field} å¹¾ä½•...")
    
    out_fields_str = ','.join(out_fields)
    count_url = f"{base_url}/query?where=1%3D1&returnCountOnly=true&f=json"
    
    try:
        count_response = requests.get(count_url)
        count_response.raise_for_status()
        total_count = count_response.json().get('count', 0)
        print(f"   -> æœå‹™å ±å‘Šç¸½è¨˜éŒ„æ•¸: {total_count}")
        if total_count == 0:
            print(f"âŒ éŒ¯èª¤: ArcGIS æœå‹™å ±å‘Š {id_field} ç¸½è¨˜éŒ„æ•¸ç‚ºé›¶ã€‚")
            return gpd.GeoDataFrame()
    except Exception as e:
        print(f"âŒ ç²å– {id_field} ç¸½è¨˜éŒ„æ•¸å¤±æ•—: {e}")
        return gpd.GeoDataFrame()

    all_geometry = []
    offset = 0
    
    while offset < total_count:
        print(f"   -> æ­£åœ¨ç²å–æ‰¹æ¬¡ï¼šè¨˜éŒ„ {offset} åˆ° {min(offset + MAX_RECORDS, total_count)}...")
        
        query_params = {
            'where': '1=1',
            'outFields': out_fields_str,
            'resultOffset': offset,
            'resultRecordCount': MAX_RECORDS,
            'f': 'geojson',
            'inSR': '4326', 
            'outSR': '4326',
        }
        
        query_url = f"{base_url}/query?{urlencode(query_params)}"
        
        try:
            response = requests.get(query_url)
            response.raise_for_status()
            
            gdf_batch = gpd.read_file(io.BytesIO(response.content))
            
            if gdf_batch.empty:
                print("   -> ğŸš¨ è­¦å‘Šï¼šArcGIS æœå‹™è¿”å›ç©ºæ‰¹æ¬¡ã€‚åœæ­¢ç²å–ã€‚")
                break
                
            all_geometry.append(gdf_batch)
            offset += len(gdf_batch)
            sleep(0.5) 
            
        except Exception as e:
            print(f"âŒ ç²å–æ‰¹æ¬¡æ•¸æ“šå¤±æ•— (Offset: {offset}): {e}")
            break
            
    if not all_geometry:
        print(f"âŒ éŒ¯èª¤ï¼šæœªèƒ½ç²å–ä»»ä½• {id_field} æ•¸æ“šã€‚")
        return gpd.GeoDataFrame()
        
    gdf_final = pd.concat(all_geometry, ignore_index=True)
    gdf_final = gdf_final[out_fields + ['geometry']].copy()
    
    return gdf_final

def fetch_all_meshblock_geometry(base_url: str) -> gpd.GeoDataFrame:
    """ç²å– Meshblock å¹¾ä½•ã€‚"""
    gdf_final = fetch_arcgis_geometry(base_url, 'MB_number', ['MB_number'])
    if not gdf_final.empty:
        # ğŸ’¥ ä¿®æ­£é»: æ¨™æº–åŒ– Meshblock ID ç‚º 7 ä½å­—ä¸²
        gdf_final['MB_number'] = gdf_final['MB_number'].astype(str).str.strip().str.zfill(7)
        print(f"âœ… æˆåŠŸç²å–æ‰€æœ‰ Meshblock å¹¾ä½•ç¸½è¨˜éŒ„æ•¸: {len(gdf_final)}")
    return gdf_final

def fetch_all_area_unit_geometry(base_url: str) -> gpd.GeoDataFrame:
    """ç²å– Area Unit å¹¾ä½•ã€‚"""
    out_fields = ['AU2017_V1_00', 'AU2017_V1_00_NAME']
    gdf_final = fetch_arcgis_geometry(base_url, 'AU2017_V1_00', out_fields)
    if not gdf_final.empty:
        # æ¨™æº–åŒ– Area Unit Code ç‚º 6 ä½å­—ä¸²
        gdf_final['AU_code'] = gdf_final['AU2017_V1_00'].astype(str).str.strip().str.zfill(6)
        gdf_final = gdf_final.rename(columns={'AU2017_V1_00_NAME': 'Area Unit Name'})
        print(f"âœ… æˆåŠŸç²å–æ‰€æœ‰ Area Unit å¹¾ä½•ç¸½è¨˜éŒ„æ•¸: {len(gdf_final)}")
    return gdf_final


def fetch_and_clean_police_data(crime_url: str, meshblock_url: str, area_unit_url: str) -> gpd.GeoDataFrame:
    """ä¸‹è¼‰ã€åˆä½µå’Œç¯©é¸çŠ¯ç½ªæ•¸æ“š (åŒ…å«å…©éšæ®µå¹¾ä½•åŒ¹é…å’Œæ—¥æœŸæ ¼å¼ä¿®æ­£)ã€‚"""
    print("--- 1. æ­£åœ¨è™•ç†è­¦å¯Ÿæ•¸æ“š ---")
    
    # ----------------------------------------------------
    # 1. æ•¸æ“šä¸‹è¼‰å’Œåˆå§‹æ¸…ç†
    # ----------------------------------------------------
    print("   -> æ­£åœ¨ä¸‹è¼‰å¤§å‹çŠ¯ç½ªæ•¸æ“šæ–‡ä»¶...")
    try:
        crime_data_response = requests.get(crime_url)
        crime_data_response.raise_for_status()
        df_crime = pd.read_csv(io.BytesIO(crime_data_response.content), encoding='latin1')
        
        # æ ¸å¿ƒæ¬„ä½æ¸…ç†
        df_crime.columns = df_crime.columns.str.strip()
        df_crime.columns = [col.replace('Ã¯Â»Â¿', '').strip() for col in df_crime.columns]
        
        CRIME_MONTH_COL_NAME = 'Year Month'
        if CRIME_MONTH_COL_NAME not in df_crime.columns: raise KeyError(f"æ‰¾ä¸åˆ°å¿…è¦çš„ '{CRIME_MONTH_COL_NAME}' æ¬„ä½ã€‚")
            
        meshblock_cols = [col for col in df_crime.columns if 'meshblock' in col.lower()]
        if 'Meshblock' not in df_crime.columns and meshblock_cols:
            df_crime.rename(columns={meshblock_cols[0]: 'Meshblock'}, inplace=True)
        elif 'Meshblock' not in df_crime.columns:
            raise KeyError(f"æ‰¾ä¸åˆ°å¿…è¦çš„ 'Meshblock' æ¬„ä½ã€‚")
        
        print(f"   -> çŠ¯ç½ªæ•¸æ“šåŸå§‹è¨˜éŒ„æ•¸: {len(df_crime)}") 
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰æˆ–è™•ç†çŠ¯ç½ªæ•¸æ“šå¤±æ•—: {e}")
        raise
    
    # ----------------------------------------------------
    # 2. ç²å–æ‰€æœ‰å¹¾ä½•æ•¸æ“š
    # ----------------------------------------------------
    gdf_meshblocks = fetch_all_meshblock_geometry(meshblock_url)
    gdf_area_units = fetch_all_area_unit_geometry(area_unit_url)
    
    if gdf_meshblocks.empty and gdf_area_units.empty:
        return gpd.GeoDataFrame()

    # æ¨™æº–åŒ–è­¦å¯Ÿæ•¸æ“šçš„ Meshblock ID (7 ä½å­—ä¸²)
    df_crime['Meshblock'] = df_crime['Meshblock'].astype(str).str.strip().str.zfill(7)
    
    # æ‡‰ç”¨ TA æ¸…ç†å‡½æ•¸ä¸¦ç¯©é¸å¥§å…‹è˜­
    df_crime['Territorial Authority Cleaned'] = df_crime['Territorial Authority'].astype(str).apply(clean_territorial_authority)
    df_auckland = df_crime[df_crime['Territorial Authority Cleaned'].isin(AUCKLAND_AUTHORITIES_CLEANED)].copy()
    print(f"   -> å¥§å…‹è˜­TAéæ¿¾å¾Œè¨˜éŒ„æ•¸: {len(df_auckland)}")
    
    # ----------------------------------------------------
    # 3. éšæ®µä¸€ï¼šMeshblock åŒ¹é… (å„ªå…ˆåŒ¹é…)
    # ----------------------------------------------------
    print("   -> åŸ·è¡Œéšæ®µä¸€ï¼šMeshblock å¹¾ä½•åŒ¹é…...")
    df_merged = df_auckland.merge(
        gdf_meshblocks[['MB_number', 'geometry']], 
        left_on='Meshblock', 
        right_on='MB_number', 
        how='left'
    )
    df_merged = df_merged.rename(columns={'geometry': 'geometry_mb'})
    
    unmatched_count_1 = df_merged['geometry_mb'].isna().sum()
    print(f"   -> éšæ®µä¸€ï¼šæˆåŠŸåŒ¹é…è¨˜éŒ„æ•¸: {len(df_merged) - unmatched_count_1}")
    print(f"   -> éšæ®µä¸€ï¼šæœªåŒ¹é…è¨˜éŒ„æ•¸: {unmatched_count_1}")
    
    if unmatched_count_1 > 0 and not gdf_area_units.empty:
        # ----------------------------------------------------
        # 4. éšæ®µäºŒï¼šArea Unit åŒ¹é… (é‡å°æœªåŒ¹é…çš„è¨˜éŒ„)
        # ----------------------------------------------------
        print("   -> åŸ·è¡Œéšæ®µäºŒï¼šå˜—è©¦ä½¿ç”¨ Area Unit å¹¾ä½•åŒ¹é…æœªåŒ¹é…çš„è¨˜éŒ„...")
        
        # æå–æœªåŒ¹é…çš„è¡Œ
        df_unmatched = df_merged[df_merged['geometry_mb'].isna()].copy()
        
        # å‡è¨­ Area Unit Code çš„æ ¼å¼æ˜¯ Meshblock Code çš„å‰ 6 ä½
        df_unmatched['AU_code_match'] = df_unmatched['Meshblock'].str[:6]
        
        df_area_merged = df_unmatched.merge(
            gdf_area_units[['AU_code', 'geometry']],
            left_on='AU_code_match',
            right_on='AU_code',
            how='left'
        )
        df_area_merged = df_area_merged.rename(columns={'geometry': 'geometry_au'})
        
        # å¡«å……ä¸»æ•¸æ“šæ¡†
        df_merged.loc[df_merged['geometry_mb'].isna(), 'geometry_mb'] = df_area_merged['geometry_au'].values
        df_merged = df_merged.rename(columns={'geometry_mb': 'geometry'}) # æœ€çµ‚ä½¿ç”¨çš„å¹¾ä½•æ¬„ä½
        
        unmatched_count_2 = df_merged['geometry'].isna().sum()
        print(f"   -> éšæ®µäºŒï¼šå†æ¬¡æœªåŒ¹é…è¨˜éŒ„æ•¸: {unmatched_count_2}")
        print(f"   -> ç¸½åŒ¹é…æˆåŠŸè¨˜éŒ„æ•¸: {len(df_merged) - unmatched_count_2}")
    else:
        df_merged = df_merged.rename(columns={'geometry_mb': 'geometry'}) # å¦‚æœæ²’æœ‰ç¬¬äºŒéšæ®µï¼Œç›´æ¥é‡å‘½å
        unmatched_count_2 = unmatched_count_1

    # ----------------------------------------------------
    # 5. æ•¸æ“šæ¸…ç†å’Œé™¤éŒ¯è¼¸å‡º
    # ----------------------------------------------------
    
    # ğŸ’¥ æ ¸å¿ƒä¿®æ­£é»ï¼šæ˜ç¢ºæŒ‡å®šæ—¥æœŸæ ¼å¼ç‚º D/M/YYYY
    print("   -> æ­£åœ¨è½‰æ›æ—¥æœŸæ ¼å¼ (ä½¿ç”¨ %d/%m/%Y)...")
    df_merged[CRIME_MONTH_COL_NAME] = pd.to_datetime(
        df_merged[CRIME_MONTH_COL_NAME], 
        format='%d/%m/%Y',  # <-- é—œéµä¿®æ­£
        errors='coerce' 
    )
    
    df_final = df_merged.copy()

    df_final = df_final.rename(columns={
        'ANZSOC Division': 'OffenceType',     
        'Territorial Authority Cleaned': 'PoliceDistrict', 
        CRIME_MONTH_COL_NAME: 'CrimeMonth'
    })
    
    # è¼¸å‡ºé™¤éŒ¯ CSV (ä¸åŒ…å«å¹¾ä½•æ•¸æ“šï¼Œä½†æœ‰å…¶ä»–æ‰€æœ‰æ¬„ä½)
    DEBUG_CSV_FILE = os.path.join(OUTPUT_DIR, 'auckland_crime_debug.csv')
    df_final.drop(columns=['geometry']).to_csv(DEBUG_CSV_FILE, index=False, encoding='utf-8') 
    print(f"âœ… é™¤éŒ¯æ–‡ä»¶ (auckland_crime_debug.csv) è¼¸å‡ºåˆ° {DEBUG_CSV_FILE}")

    # æª¢æŸ¥å’Œåˆªé™¤ç„¡æ•ˆè¡Œ
    missing_geometry_count = df_final['geometry'].isna().sum()
    print(f"   -> ğŸš¨ æª¢æŸ¥: ç¶“éå…©éšæ®µåŒ¹é…å¾Œï¼Œç¼ºå°‘å¹¾ä½•åœ–å½¢çš„è¨˜éŒ„æ•¸: {missing_geometry_count}")
    
    # åˆªé™¤æ²’æœ‰æœ‰æ•ˆå¹¾ä½•åœ–å½¢ã€çŠ¯ç½ªæœˆä»½æˆ–çŠ¯ç½ªé¡å‹çš„è¡Œ
    initial_valid_count = len(df_final)
    df_final.dropna(subset=['geometry', 'CrimeMonth', 'OffenceType'], inplace=True)
    
    print(f"âœ… è­¦å¯Ÿæ•¸æ“šè™•ç†å®Œæˆã€‚æœ€çµ‚ç”¨æ–¼åˆ†æçš„è¨˜éŒ„æ•¸: {len(df_final)}ã€‚")
    if len(df_final) < initial_valid_count and len(df_final) == 0:
         print("âš ï¸ è­¦å‘Š: æ‰€æœ‰è¨˜éŒ„å‡ç”±æ–¼ç¼ºä¹å¹¾ä½•ã€æ—¥æœŸæˆ–çŠ¯ç½ªé¡å‹ä¿¡æ¯è€Œè¢«åˆªé™¤ã€‚")
    
    gdf_crime = gpd.GeoDataFrame(
        df_final.drop(columns=['MB_number', 'Territorial Authority']),
        geometry='geometry', 
        crs="EPSG:4326"
    )
        
    return gdf_crime[['OffenceType', 'PoliceDistrict', 'CrimeMonth', 'geometry']]


# --- 3. ç²å–è·¯ç·šå¹¾ä½• (ä¿æŒä¸è®Š) ---
def fetch_route_geometry() -> gpd.GeoDataFrame:
    """ç²å–å·´å£«è·¯ç·šå¹¾ä½•æ•¸æ“šã€‚"""
    print("--- 2. æ­£åœ¨ç²å– AT è·¯ç·šå¹¾ä½• ---")
    try:
        arcgis_response = requests.get(ARCGIS_ROUTES_URL)
        arcgis_response.raise_for_status() 
        gdf_routes = gpd.read_file(io.BytesIO(arcgis_response.content))
        
        gdf_routes.rename(columns={'ROUTENUMBER': 'Route No'}, inplace=True) 
        gdf_routes = gdf_routes[gdf_routes['MODE'] == 'Bus'].copy()
        gdf_routes = gdf_routes[['Route No', 'geometry']].copy()
        gdf_routes['Route No'] = gdf_routes['Route No'].astype(str)
        
        print(f"âœ… æˆåŠŸç²å– {len(gdf_routes)} æ¢å·´å£«è·¯ç·šå¹¾ä½•ã€‚")
        return gdf_routes
    except Exception as e:
        print(f"âŒ ç²å– ArcGIS æ•¸æ“šå¤±æ•—: {e}")
        raise


# --- 4. ç©ºé–“åˆ†æå’Œæ•¸æ“šå½™ç¸½ (ä¿æŒä¸è®Š) ---

def analyze_and_aggregate(gdf_routes: gpd.GeoDataFrame, gdf_crime: gpd.GeoDataFrame):
    """åŸ·è¡Œç©ºé–“é€£æ¥ã€è¨ˆç®—çµ±è¨ˆæ•¸æ“šä¸¦ç”Ÿæˆ GeoJSON å’Œ JSON æ–‡ä»¶ã€‚"""
    print("--- 3. åŸ·è¡Œç©ºé–“åˆ†æå’Œæ•¸æ“šå½™ç¸½ ---")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True) 
    
    if gdf_crime.empty:
        print("âš ï¸ è­¦å‘Šï¼šç”±æ–¼æ²’æœ‰æœ‰æ•ˆçš„å¥§å…‹è˜­çŠ¯ç½ªæ•¸æ“šï¼Œè·³éç©ºé–“åˆ†æã€‚")
        min_date = 'N/A'
        max_date = 'N/A'
        empty_geojson_output(gdf_routes) 
        empty_stats_output(min_date, max_date)
        return

    # 1. å‰µå»º 50 ç±³ç·©è¡å€
    gdf_routes_proj = gdf_routes.to_crs(epsg=2193) 
    gdf_routes_buffer = gdf_routes_proj.copy()
    gdf_routes_buffer['geometry'] = gdf_routes_buffer.geometry.buffer(50) 
    
    # 2. æŠ•å½±çŠ¯ç½ªæ•¸æ“š
    gdf_crime_proj = gdf_crime.to_crs(epsg=2193)
    
    # 3. ç©ºé–“é€£æ¥ (Spatial Join)
    crime_counts = gpd.sjoin(gdf_crime_proj, gdf_routes_buffer.reset_index(), how='inner', predicate='intersects')
    
    print(f"   -> ç©ºé–“é€£æ¥å¾Œçš„çŠ¯ç½ªäº‹ä»¶è¨˜éŒ„æ•¸: {len(crime_counts)}") 

    if crime_counts.empty:
        print("âš ï¸ è­¦å‘Šï¼šæ²’æœ‰çŠ¯ç½ªäº‹ä»¶è½åœ¨ä»»ä½•å·´å£«è·¯ç·šçš„ 50 ç±³ç·©è¡å€å…§ã€‚")
        min_date = 'N/A'
        max_date = 'N/A'
    else:
        min_date = crime_counts['CrimeMonth'].min().strftime('%Y-%m-%d')
        max_date = crime_counts['CrimeMonth'].max().strftime('%Y-%m-%d')

    # 5. çµ±è¨ˆæ¯æ¢è·¯ç·šçš„çŠ¯ç½ªç¸½æ•¸
    total_crime_summary = crime_counts.groupby('index_right').size().reset_index(name='Total_Crime_Count')
    
    # 6. å½™ç¸½çŠ¯ç½ªç´°ç¯€ (è¶¨å‹¢å’Œé¡å‹)
    crime_details = {
        'metadata': {
            'crime_period_start': min_date,
            'crime_period_end': max_date,
            'buffer_distance_m': 50,
            'data_source': 'NZ Police (Full Available Dataset) merged with NZ Meshblock/Area Unit Geometry'
        },
        'routes': {}
    }
    
    for route_index in total_crime_summary['index_right'].unique():
        route_data = crime_counts[crime_counts['index_right'] == route_index]
        route_no = gdf_routes_buffer.loc[route_index, 'Route No']
        
        monthly_trend = route_data.groupby(route_data['CrimeMonth'].dt.to_period('M')).size().to_dict()
        monthly_trend = {str(k): int(v) for k, v in monthly_trend.items()}
        
        type_breakdown = route_data['OffenceType'].value_counts().to_dict()
        type_breakdown = {k: int(v) for k, v in type_breakdown.items()}
        
        crime_details['routes'][route_no] = {
            'monthly_trend': monthly_trend,
            'type_breakdown': type_breakdown
        }

    # 7. å°‡ç¸½çŠ¯ç½ªè¨ˆæ•¸åˆä½µå›è·¯ç·š GeoDataFrame
    gdf_results = gdf_routes_buffer.reset_index().merge(total_crime_summary, 
                                                        left_on='index', 
                                                        right_on='index_right', 
                                                        how='left')
    gdf_results['Total_Crime_Count
